<table>
  <tbody>
    <tr>
      <th>嘉宾介绍</th>
      <th>演讲介绍</th>
    </tr>

<tr>
    <td>
        <strong>Rob Hyndman</strong>
        <p>Rob J Hyndman is Professor of Statistics in the Department of Econometrics and Business Statistics at Monash University and Director of the Monash University Business & Economic Forecasting Unit. Since 2005, he has been Editor-in-Chief of the International Journal of Forecasting and a Director of the International Institute of Forecasters.</p>

        <a class="more collapsed" href="##" data-toggle="collapse" data-target="#more-rob">查看详情</a>

        <div id="more-rob" class="collapse">
        <p>He completed a Science honours degree at the University of Melbourne in 1988 and a PhD on nonlinear time series modelling at the same university in 1992. After lecturing at his alma mater for two years, he moved to Monash University as a lecturer in 1995 where he has been ever since. He was promoted to a personal chair in 2003.</p>

        <p>Rob is the author of over 100 research papers in statistical science. In 2007, he received the Moran medal from the Australian Academy of Science for his contributions to statistical research, especially in the area of statistical forecasting. He is best known for his research on exponential smoothing, hierarchical forecasting, demographic forecasting and nonparametric smoothing. He has an h-index of 42 with 20 publications receiving over 100 citations each.</p>

        <p>Rob is the coauthor of "Forecasting: methods and applications" (Wiley, 1998) with Makridakis and Wheelwright, and more recently of a free online textbook with George Athanasopoulos. He is also the founder of OTexts --- an online textbook publishing platform, and Cross-validated --- an online question and answer service in statistics and machine learning.</p>

        <p>For 30 years, Rob has maintained an active consulting practice, assisting hundreds of companies and organizations. His recent consulting work has involved forecasting electricity demand, tourism demand, the Australian government health budget and case volume at a US call centre.</p>
        </div>
    </td>
    <td>
        <p>It is becoming increasingly common for organizations to regularly forecast many thousands or even millions of time series. For example, manufacturing companies often require weekly forecasts of demand for thousands of products at dozens of locations in order to plan distribution and maintain suitable inventory stocks. I will describe the best available algorithms for automatically forecasting large collections of univariate time series. These are implemented in the forecast package for R.</p>

        <a class="more collapsed" href="##" data-toggle="collapse" data-target="#more-rob2">查看详情</a>

        <div id="more-rob2" class="collapse">
        <p>In many applications, there are also aggregation constraints that must be imposed. For example, a manufacturing company can disaggregate total demand for their products by country of sale, retail outlet, product type, package size, and so on. As a result, there can be millions of individual time series to forecast at the most disaggregated level, plus additional series to forecast at higher levels of aggregation. The disaggregated forecasts should add up to the forecasts of the aggregated data; this is known as "forecast reconciliation". </p>

        <p>The optimal reconciliation method involves fitting an ill-conditioned linear regression model that is impossible to estimate using standard regression methods. I will demonstrate how this problem has been solved in R, making it possible for large scale forecasting to be implemented in practice.</p>
        </div>
    </td>
</tr>


<tr>
    <td>
        <strong>Michael O'Neill</strong>
        <p>Michael O'Neill BActS Hons/LLB, PhD, FIAA: Michael was awarded a PhD in Finance at the University of Queensland, Australia, in 2014. Previously he completed a combined degree at the Australian National University in 2005, graduating with a Actuarial Studies with First Class Honours and a University Medal, and a Bachelor of Laws. Michael qualified as a Fellow of the Actuaries Institute in 2007, and has been a director on the Institute's Board since 2008. Michael's research interests lie in volatility modelling and forecasting, state-price density analysis and analysis of supply and demand for volatility. Michael has worked as an equities analyst and portfolio manager at Investors Mutual Ltd since 2008. The company has received several awards as Australian fund manager of the year, most recently by Morningstar in 2015.</p>
    </td>
    <td>
        <p>Exchange traded volatility markets have grown substantially since VIX futures were launched by the CBOE in 2004, followed by VIX options in 2006 and VIX ETPs in 2009. Daily open interest for volatility products is now in the tens of billions of dollars. Motivated by the wide range of options to trade stock market volatility on the exchange, Bollen, O'Neill and Whaley (2015) analyse the supply and demand for volatility. The aim of the study is to use high frequency data to determine where price discovery occurs, and whether the lead/lag relations between prices of exchange traded volatility have changed over time. Data are recorded at high frequency, and trading intensity has increased in these markets. In the analysis of lead/lag relations, the study calculates the Hiyashi and Yoshida (2005) covariance matrix, in order to avoid any distortions and spurious correlations that might otherwise be caused by non-synchronous trading at high frequency. The calculation of this covariance matrix in R is computationally intensive; the estimator makes use of all data, regardless of the time intervals between samples. From this covariance matrix the authors draw conclusions for price discovery in markets for volatility and the length of leads/lags between markets, particularly where cost effective arbitrage is not possible.</p>
    </td>
</tr>


<tr>
    <td>
        <strong>Garry Khemka</strong>
        <p>Dr Garry Khemka did a Bachelor of Economics (Hons.) from Jadavpur University (Kolkata) before moving to Australia to pursue his education in Actuarial Studies. He completed a Masters of Actuarial Studies (with distinction) at the Australian National University and stayed on to complete his PhD in 2013. He is also a Fellow of the Institute of Actuaries of Australia. He was a lecturer at the Australian National University before joining Bond University in 2015 as one of the founding members of the Actuarial Science department.</p>

        <a class="more collapsed" href="##" data-toggle="collapse" data-target="#more-garry">查看详情</a>

        <div id="more-garry" class="collapse">
        <p>Dr Khemka is a budding early career academic with publications in some of the top Actuarial journals, along with a wide number of conference presentations and keynote speeches. His current research interests span retirement planning and superannuation, long term care insurance products, disability income insurance and personal finance. He has also received various research grants, as a testament of his growing skill and expertise.</p>
        </div>
    </td>
    <td>
        <p>For a retiree who must maintain both investment and longevity risks, we consider the impact on decision making of focusing on an objective relating to the terminal wealth at retirement, instead of a more correct objective relating to a retirement income. Both a shortfall and a utility objective are considered; we argue that shortfall objectives may be inappropriate due to distortion in results with non-monotonically correlated economic factors. The modelling undertaken uses a dynamic programming approach in conjunction with Monte-Carlo simulations of future experience of an individual to make optimal choices. We find that the type of objective targeted can have a significant impact on the optimal choices made, with optimal equity allocations being up to 30% higher and contribution amounts also being significantly higher under a retirement income objective as compared to a terminal wealth objective. The result of these differences can have a significant impact on retirement outcomes.</p>
    </td>
</tr>


<tr>
    <td>
        <strong>李舰</strong>
        <p>李舰，毕业于中国人民大学统计学院（本科）和北京大学软件与微电子学院（研究生），现就职于堡力山集团，担任副总。是Rweibo、Rwordseg、tmcn等R包的作者，《数据科学中的R语言》的作者，还参与翻译了《R语言核心技术手册》和《机器学习与R语言》。
个人主页：<a href="http://jianl.org">http://jianl.org</a>。</p>
    </td>
    <td>
        <p>在大数据时代里，人们处理的数据早已超出了传统的数值和文本，尤其在移动互联网的时代下，社交网络数据成了非常关键的数据来源。社交网络分析（Social Network Analysis，SNA）是在传统的图与网络的理论之上对社交网络数据进行分析的方法，如今已经成了大数据分析不可或缺的一部分。本次报告将会介绍SNA的相关知识以及R中的实现方式，并结合业界常用的Gephi软件进行图形化的操作。此外，还会通过案例分享来说明社交网络分析的方法在业界的应用。</p>
    </td>
</tr>


<tr>
    <td>
        <strong>Terry O'Neill</strong>
        <p>Terry O'Neill is Director of Centre for Actuarial and Financial Big Data Analytics at Bond University. He is also head of Actuarial Science. Terry has a Phd from Stanford University. He is a Fellow of the Institute of Mathematical Statistics, Fellow of the American Statistical Association and elected member of the International Statistical Institute. He was previously Director of the Research School of Finance, Actuarial Science and Applied Statistics at the Australian National University.</p>
    </td>
    <td>
        <p>R is a well documented programming environment with a strong academic following in many countries. It started with a core user group of statisticians, but now has a strong user base spread across a diverse range of disciplines. The open source nature of the product and the fact that it is used across disciplines including statistics, demography, economics and finance make it an ideal product for actuaries. It has already been embraced by many of the top actuarial industry bodies, research and teaching institutions. This talk will focus on the use of R at the forefront of data science in the field of Actuarial Science.</p>
    </td>
</tr>


<tr>
    <td>
        <strong>李丰</strong>
        <p>李丰，中央财经大学统计与数学学院，讲师，硕士研究生导师，院长助理。教育背景：2008 — 2013 统计学 博士，瑞典斯德哥尔摩大学统计学系；2003 — 2007 统计学 本科，中国人民大学统计学院。E-mail：feng.li@cufe.edu.cn。Web：<a href="http://feng.li">http://feng.li</a>。</p>
    </td>
    <td>
        <p>Copula tail-dependence modeling with flexible marginal distributions is widely used in financial time series. Most of the available Copula approaches for estimating tail-dependence are restricted within certain types of bivariate copulas due to computational complexity. We propose a general Bayesian approach for jointly modeling high-dimensional tail-dependence with general copulas functionals. Our method allows for variable selection among the covariates in the copula tail-dependence parameters. We apply a novel sampling technique into the posterior inference where the likelihood function is estimated from a random subset of the data, resulting in substantially fewer density MCMC evaluations.</p>
    </td>
</tr>


<tr>
    <td>
        <strong>邓一硕</strong>
        <p>邓一硕，北京大家玩科技有限公司（懒投资）CFO、副总裁，风险控制委员会委员；毕业于中央财经大学统计与数学学院，毕业后曾效力于首钢集团计财部，2014年起加入北京大家玩科技有限公司（懒投资），历任金融项目部总监、财务总监。统计之都理事会理事，曾翻译《R语言核心技术手册》等书籍。</p>
    </td>
    <td>
        <p>2014年以来，随着互联网金融企业数量的持续增加以及股票市场的繁荣，行业竞争骤然加剧，为了保持竞争力，互联网金融企业必须不断做出产品创新。在此背景下，可灵活存取的活期类投资产品、挂钩股市的结构化产品纷纷面市。</p>
        <p>产品创新在为企业带来竞争优势的同时，也为企业带来了运营管理和风险控制上的挑战：像活期类产品就要求企业能够对产品的流动性做出较为精准的预测和管理，以满足投资者的赎回要求，因而，需要企业去不断发掘投资者的申购赎回规律；像债权转让类产品，为了引导投资者理性转让，增加市场流动性，需要对转让价格进行引导，此时需要动态告知投资者项目转让成功的概率。</p>
        <a class="more collapsed" href="##" data-toggle="collapse" data-target="#more-yishuo">查看详情</a>

        <div id="more-yishuo" class="collapse">
        <p>此外，为了大量获客，企业常常推出力度较大的推广活动，如注册返现、投资返现等，这类活动往往会吸引众多职业羊毛党来薅羊毛，其中不乏伪造信息的「黑羊毛党」，「黑羊毛党」的存在会造成推广成本的剧增，从而降低推广质量，因而，如何甄别「黑羊毛党」也是一个很有意思的挑战。</p>
        <p>所有这些都需要根据数据和模型进行解决。</p>
        </div>
    </td>
</tr>


<tr>
    <td>
        <strong>任坤</strong>
        <p>任坤，毕业于厦门大学金融系和王亚南经济研究院，毕业后在深圳从事量化私募基金的策略研发和工具开发，是pipeR、rlist、formattable等扩展包的作者，在个人博客（<a href="http://renkun.me">http://renkun.me</a>）中写了数十篇文章讨论数据分析相关工具、R语言高级编程等主题。</p>
    </td>
    <td>
        <p>量化交易的核心是策略，而好的策略离不开数据分析、交易执行和风险控制。R语言作为数据分析、建模、可视化的重要工具，加上丰富的扩展包资源和快速成长的社区，可以显著提升效率，在量化研究方面起到重要作用。本报告将以量化策略的框架为基础，以具体案例为切入点，讨论量化策略从思想到回测、实盘以及分析环节中的方法和问题。</p>
    </td>
</tr>


<tr>
    <td>
        <strong>史彦琳</strong>
        <p>史彦琳，于2014年6月在澳大利亚国立大学(ANU)取得统计学博士学位，目前在该校金融、精算与统计学院担任统计学讲师。研究方向包括时间序列分析，金融计量经济学和应用统计。曾在多个SSCI期刊上发表论文，并多次在国际学术会议如“International Congress on Modelling and Simulation”和“China Meeting of Econometric Society”上做过宣讲。</p>
    </td>
    <td>
        <p>Markov Regime-Switching Generalized autoregressive conditional heteroskedastic (MRS-GARCH) model is a widely used approach to model the financial volatility with potential structural breaks. The original innovation of the MRS-GARCH model is assumed to follow the Normal distribution, which cannot accommodate fat-tailed properties commonly existing in financial time series. Many existing studies point out that this problem can lead to inconsistent estimates.</p>

        <a class="more collapsed" href="##" data-toggle="collapse" data-target="#more-yanlin">查看详情</a>

        <div id="more-yanlin" class="collapse">
        <p>To overcome it, the Student's t-distribution and General Error Distribution (GED) are the two most popular alternatives. However, a recent study points out that the Student's t-distribution lacks stability. Instead, it incorporates the alpha-stable distribution in the GARCH-type model. The issue of the alpha-stable distribution is that its second moment does not exist. To solve this problem, the tempered stable distribution, which retains most characteristics of the alpha-stable distribution and has defined moments, is a natural candidate. In this paper, we conduct a series of simulation studies to demonstrate that MRS-GARCH model with tempered stable distribution consistently outperform that with Student's t-distribution and GED. The computational details of estimating the density function of the tempered stable distribution is also discussed. Further, our empirical study on the S&amp;P 500 daily return volatility generates robust results. Therefore, we argue that the tempered stable distribution could be a widely useful tool for modelling the financial volatility in general contexts with a MRS-GARCH-type specification.</p>
        </div>
    </td>
</tr>


<tr>
    <td>
        <strong>刘路</strong>
        <p>刘路，中南大学数学与统计学院，研究员。在Journal of symbolic logic和Transaction of AMS上发表论文若干。目前研究方向：过程统计、大偏差理论。<a href="http://r.m.baidu.com/4c1arq7">http://r.m.baidu.com/4c1arq7</a></p>
    </td>
    <td>
        <p>For a given sparse graph sequence $G^N$, we give definition of convergence of graph structure. We study a colouring process.  At each time $t$, one uncoloured node, $\pi(t)$, is coloured by a state in $S$. The colouring state is random with distribution $v_t\in P(S)$. Where $v_t\in P(S)$ depends on time $t$, the subgraph (with colour) within distance $d$ to node $\pi(t)$, denoted by $G_{\pi(t),d}^{N,S,t}$. We prove that for a convergent sequence of sparse graph, any such colouring strategy, $v_t$, which is bounded away from 0 and 1, induces a convergent sequence of stochastic process on coloured graph structure. Actually, what we really prove is somewhat stronger.</p>
        <p>We point out the possible applications on large deviation theorems and control problems.</p>
    </td>
</tr>


<tr>
    <td>
        <strong>汤耀华</strong>
        <p>汤耀华，香港大学统计与精算系在读博士，主要研究方向是深度学习在机器翻译和股票交易两个领域的应用。</p>
    </td>
    <td>
        <p>In this research, we consider using recurrent neural network, especially Long-Short Term Memory(LSTM), to guide daily trading of stocks. This is based on the dynamic changing nature of stocks' prices. Unlike the previous researches that only capable of handling a single stock or index, we combine portfolio management and stock selection into a united model. The performance functions that we consider for reinforcement learning are profit or wealth. Experimental results show that our model outperforms common baseline strategies.</p>
    </td>
</tr>


<tr>
    <td>
        <strong>曾若辰</strong>
        <p>曾若辰，香港大学统计及精算系在读博士。</p>
    </td>
    <td>
        <p>The traditional threshold autoregressive model only describes the dynamics of the conditional mean process, so they could be inadequate to capture nonlinearities in the entire quantile process, when different regimes that coincide in the mean process fail to coincide in quantile processes. To capture different behaviors across different quantiles, Galvao et al.(2011) proposed the threshold quantile autoregressive models, built on top of the quantile autoregressive model introduced by Koenker and Xiao (2006).<p>

        <a class="more collapsed" href="##" data-toggle="collapse" data-target="#more-ruochen">查看详情</a>

        <div id="more-ruochen" class="collapse">
        <p>Empirical study has found that the for US monthly unemployment growth series, different threshold autoregressive processes for different quantiles were proposed. On the other hand, hysteresis has been widely observed in many macroeconomic series. Li et al. (2012) proposed the hysteretic autoregressive model to incorporate hysteresis into the classical two-regime self-exciting threshold autoregressive model by introducing a more flexible regime switching mechanism. It thus motivates the proposal of a quantile hysteretic autoregressive model that can capture hysteresis in the entire process.</p>
        </div>
    </td>
</tr>


<tr>
    <td>
        <strong>曾锦山</strong>
        <p>曾锦山，男，江西师范大学计算机信息工程学院副教授。曾锦山于2008年7月获得西安交通大学理学学士学位，同年9月进入该校应用数学系攻读研究生，并于2015年6月获得西安交通大学理学博士学位。自2015年9月起在江西师范大学计算机信息工程学院任职。从2013年至2014年在美国加州大学洛杉矶分校(UCLA)访问。研究兴趣主要包括机器学习、分布式优化、稀疏优化、及其信号处理。现已发表SCI论文11篇，国际会议论文1篇，授权专利1项。目前担任SIAM Journal on Scientific Computing, IEEE Trans. Signal Processing/ Image Processing， IET Signal Procrocessing和Science China Information Science等多个学术期刊的审稿人。</p>
    </td>
    <td>
        <p>在近年来的稀疏建模研究中，由于非凸罚在诱导稀疏性方面往往比凸罚更有优势， 从而非凸罚受到广泛关注。然而与凸罚方法相比，对应的非凸罚算法的收敛性分析通常更具挑战性。本报告将主要介绍一类用于求解稀疏性问题的非凸阈值迭代算法及其收敛性理论，并将所建立的算法与理论应用于典型的稀疏性问题――合成孔径雷达(SAR)成像。数值实验揭示了算法在SAR成像应用中的有效性。</p>
    </td>
</tr>


<tr>
    <td>
        <strong>朱雪宁</strong>
        <p>朱雪宁，本科毕业于中山大学数学与应用数学专业，现为北京大学光华管理学院商务统计系在读博士生。研究方向为社交网络分析，搜索引擎营销等。</p>
    </td>
    <td>
        <p>We consider here a large-scale social network with a continuous response observed for each node at equally spaced time points. The responses from different nodes constitute an ultrahigh dimensional vector, whose time series dynamics is to be investigated. In the meanwhile, the network structure needs to be taken into consideration. To this end, we propose a network vector autoregres-sive (NAR) model. NAR models each node’s response at a given time point as a linear combination of (a) its previous value, (b) the average of its connected neighbors, (c) a set of node-specific covariates, and (d) an independent noise.</p>
        <a class="more collapsed" href="##" data-toggle="collapse" data-target="#more-xuening">查看详情</a>

        <div id="more-xuening" class="collapse">
        <p>The corresponding coefficients are referred to as the momentum effect, the network effect, and the nodal effect respectively. The second-order stationary conditions for the NAR model are derived, and it is found that the network structure plays an important role. In order to estimate the NAR model, an ordinary least squares type estimator is developed, and its asymptotic properties are investigated. We further illustrate the usefulness of the NAR model through a number of interesting potential applications. Simulation studies and an empirical example are presented to demonstrate the performance of the newly proposed methodology. (Joint work with Rui Pan, Guodong Li, and Hansheng Wang.)</p>
        </div>
    </td>
</tr>


<tr>
    <td>
        <strong>罗立辉</strong>
        <p>罗立辉，中欧联合培养博士，副研究员。参与了中科院第一个大数据中心的建设工作：寒旱区科学大数据中心。主要研究方向包括冻土分布与灾害模型、寒区生态—水文建模、寒区灾害预警与决策支持。</p>
    </td>
    <td>
        <p>地学建模聚焦于地球系统在时间和空间上的动态变化，从模型的机理和物理过程出发，如何用R来制备地学时空数据，开发地学模型，并进行模拟计算与可视化？如何将大量的地学模型进行耦合，以形成新的更为庞大的、复杂的地学模型？如何将大量的地学模型拆分成独立的单元模块，然后从已拆分的众多模块中寻找适合的模块进行耦合，形成一个新的地学模型？开发和优选不同地学模型以组合成新模型，由此创建的地学建模环境（平台）将为地学模型集成创造出各种可能。</p>
    </td>
</tr>


<tr>
    <td>
        <strong>张源源</strong>
        <p>张源源，毕业于吉林大学信息与计算科学专业。先后在友盟、百度、乐动力等多家公司从事与数据和算法相关的工作。</p>
    </td>
    <td>
        <p>相比PC电脑，手机因为有了更多更好的传感器，所以增加了很多比电脑好玩的特性。</p>
        <p>作为业界最早的一批使用传感器数据做成产品的公司，乐动力在这个过程中进行了一些机器学习实践。</p>
        <p>本次演讲主要讲述计步、自动识别运动、轨迹优化、自适应学习步长等模块背后的机器学习探索，以及在电量、内存、后台不能稳定运行等条件的限制下，如何取得尽量好的结果，最后剖析了乐动力的产品架构和发展历史，期望能抛砖引玉，启发大家对数据改变生活的认识。</p>
    </td>
</tr>


<tr>
    <td>
        <strong>肖凯</strong>
        <p>肖凯，一个喜欢折腾数据的人，《数据科学中的R语言》作者之一，目前供职于1号店商务智能部。</p>
    </td>
    <td>
        <p>介绍数据分析领域两种主流工具的特点，以及二者的协同配合。</p>
    </td>
</tr>


<tr>
    <td>
        <strong>任万凤</strong>
        <p>任万凤，毕业于北京大学数学学院应用统计硕士，研究方向为移动互联网用户分析、社交网络兴趣识别、精准营销等。曾效力于天猫BI部，参与双11商品流量调控及预测等相关项目。毕业后加入创业团队诸葛IO(zhugeio.com)，担任资深数据分析师，从事社交用户兴趣、精细化运营、用户行为路径等相关工作。曾主要翻译《Tableau数据可视化实战》等书籍。</p>
    </td>
    <td>
        <p>互联网时代的降临使得疯狂的创业者们笑开了颜，但不幸的是互联网寒冬也伴随而来，人口红利也逐渐消失，因此创业者更需要把有限的资本花在刀刃上，找到下一个产品红利点。若想在这样的大环境下实现价值用户的留存、新增用户增长率的提升，就必须对产品本身和用户群体有深入的数据分析。而用户数据是APP的自有资产,但大部分APP却没能利用好数据价值，仍然闭着眼睛做产品，这其中用户数据的流动（用户路径）才是产品的立身之本，根据用户的核心行为路径，挖掘出最易导致用户流失的产品位置并加以优化，帮助产品快速迭代，更加贴近核心价值用户需求。</p>
        <p>本次演讲主要通过国内某著名APP进行实际的用户行为路径挖掘，找到产品的核心优化点，定位流失人群显著属性，帮助APP更好的提升用户核心行为，从而带来APP下一个核心红利点。</p>
    </td>
</tr>


<tr>
    <td>
        <strong>郎大为</strong>
        <p>郎大为, SupStat高级数据科学家，雪晴数据网专职讲师。
博客地址：<a href="http://chiffon.gitcafe.io">http://chiffon.gitcafe.io</a></p>
    </td>
    <td>
        <p>GIS地理信息可视化是可视化中难度较大，但适用范围较广的一个领域。REmap(<a href="http://lchiffon.github.io/REmap/">http://lchiffon.github.io/REmap/</a>)是基于Echarts的R包。不同于传统的静态地图，REmap为广大的数据玩家提供了一种简便、动态、可交互的地理数据可视化工具。本报告集中展示了REmap的基本功能，以及运用REmap实现的天气预报等案例。</p>
    </td>
</tr>


<tr>
    <td>
        <strong>周扬</strong>
        <p>周扬，J.D.POWER 数据分析师，擅长数据可视化及利用R作为数据处理引擎建立数据应用级数据产品原型。熟悉R, HTML5/CSS3, Python, Javasript 等工程开发。曾在国际著名期Bioinformatics（生物信息学）上发表论文两篇，在Nuclear Acid Research（核酸研究）上发表论文一篇。</p>
    </td>
    <td>
        <p>数据可视化作为数据的重要表现形式，在数据分析以及数据产出中都表现出极为重要的作用。而数据快速膨胀的今天，面向数据及数据可视化的工具和框架也迅速发展，如何在众多的工具和框架中选择适合自身数据需求的组合，成为每一个希望和正在从事数据工作的工作者需要思考的问题。演讲者作为数据可视化爱好者，希望通过自己在实现数据从端到端（即从原始数据到最终数据可视化产出物）的实际工作内容出发，以workshop的方式介绍：1）如何利用R语言作为数据处理、分析、建模引擎，提供数据可视化的有效支持；2）如何在不同数据分析需求条件下，选择数据可视化（数据呈现端）的工具；3）如何将数据处理、分析、建模的模块与数据可视化模块进行拼接和产物。</p>
    </td>
</tr>


<tr>
    <td>
        <strong>杨环</strong>
        <p>杨环，现就职于Mango-Solutions（檬果商务咨询），负责项目咨询和R语言开发。</p>
    </td>
    <td>
        <p>shiny包，用于R语言快速搭建网页交互应用，给统计计算分析代码裹上一层点击拖拽的外衣。随着shiny生态链上，大包小包落玉盘，shiny app逐渐成长为商业应用中最后一环——可视化的实操工具。主讲人将以业界开发shiny app为例，对目前shiny相关技术及前景作一分享。后端到前端，从此全栈人；玩具亦产品，人生不赢乎。</p>
    </td>
</tr>


<tr>
    <td>
        <strong>谢益辉</strong>
        <p>谢益辉，爱荷华州立大学统计学博士，现为RStudio码农一枚。</p>
    </td>
    <td>
        <p>简单谈谈作为一个R码农的一些个人经验，以R包的开发为主，包括函数的模块化、文档的自动化（roxygen2）、测试云端化（Travis CI）、文档人性化、开发社区化（Github）、应用网页化（JavaScript/htmlwidgets/Shiny/R Markdown）。</p>
    </td>
</tr>


<tr>
    <td>
        <strong>邱怡轩</strong>
        <p>邱怡轩，普渡大学统计系在读博士，统计之都理事会成员，感兴趣的领域包括统计计算与建模，R语言相关技术等。曾参与翻译《R语言编程艺术》《R数据可视化手册》《ggplot2：数据分析与图形艺术》等书籍，是showtext，rARPACK，recosystem等R软件包的作者。个人主页<a href="http://yixuan.cos.name/cn">http://yixuan.cos.name/cn</a>。</p>
    </td>
    <td>
        <p>最近的几年里，“大数据”的观念越来越深入人心，但回归到问题的本源，如何在大规模的数据上进行统计建模并计算求解，依然是一个极具挑战性的问题。即使是最基本的统计模型，在面临很大的数据量时，要在可接受的时间内完成计算也并非易事。这其中至少包含了两方面的原因：(1)许多模型的设定很简单，但并没有显式的求解公式，例如Lasso及其他众多的带惩罚项的统计模型；(2)计算机硬件的发展使得并行计算已经相当普及，但很多模型的求解算法并没有利用这一便利条件。</p>

        <a class="more collapsed" href="##" data-toggle="collapse" data-target="#more-yixuan">查看详情</a>

        <div id="more-yixuan" class="collapse">
        <p>为了克服这两方面的困难，最近几年ADMM算法（Alternating Direction Method of Multipliers）开始受到越来越多的来自统计学和机器学习领域的关注。ADMM是一种最优化算法，它主要针对带约束的凸优化问题。由于很大一部分的统计模型求解都可以归结为这一类优化问题，所以ADMM在统计学习里的应用非常广，典型的例子包括Lasso及其扩展，带正则项的广义线性模型，SVM，分位数回归，压缩感知等等。</p>
        <p>ADMM具有几方面的优势：(1)是一种迭代算法，可以根据需要的精度来设定算法终止的时机；这在大规模数据处理中非常关键，因为实际中往往可以允许一定的精度误差，但要求算法在规定的时间内完成；(2)对于许多模型具有显式的迭代公式，实施简单；(3)提供了进行分布式计算的框架，充分利用硬件资源。</p>
        <p>本报告将介绍ADMM的基本原理和算法，其分布式计算框架，以及若干常用的统计和机器学习模型在ADMM下的实现。演讲者还将介绍其编写的R软件包ADMM，展示这些模型在R中的实际用法。我们将比较ADMM软件包与其他已有软件包（如glmnet的Lasso，quantreg的中位数回归等）的性能，突出ADMM的计算优势所在。</p>
        </div>
    </td>
</tr>


<tr>
    <td>
        <strong>Wush Chi-Hsuan Wu</strong>
        <p>Wush Chi-Hsuan Wu is a PhD student from the Institute of Electrical Engineering, National Taiwan University, where he is studying online advertising. He has contributed to several R packages, including digest, RcppCNPy, knitr and ckanr.
Wush is a co-founder of Taiwan R User Group which hosts Machine Learning and Data Mining related talks weekly on Mondays. (<a href="http://www.meetup.com/taiwan-R">http://www.meetup.com/taiwan-R</a>).</p>
    </td>
    <td>
        <p>In the world of online advertising, recommendation systems produce vast amounts of categorical data. This data has many, many levels of behavioural and text data. Too many to conveniently recode in R!</p>

        <p>A good approach for pre-processing smaller categorical data is `stats::model.matrix`. However, this approach is infeasible with recommendor system data due to programming inefficiencies and pre-processing requirements(all data must be read in and synchronized). In this scenario, streaming algorithms are likely to fail while parallel algorithms become too complicated.</p>

        <a class="more collapsed" href="##" data-toggle="collapse" data-target="#more-wush">查看详情</a>

        <div id="more-wush" class="collapse">
        <p>However a solution has been found - feature hashing (also known as the hashing trick). And in 2015, many analysts use this approach to encode such data. The speaker has developed  an R package that efficiently processes vast amounts of categorical data.</p>
        <p>This package, <a href="http://cran.r-project.org/web/packages/
FeatureHashing/index.html">FeatureHashing</a> enables R users to easily apply the feature hashing with an interface similar to `stats::model.matrix`.</p>
        <p>Attendees will learn the tips of using the feature hashing, exchange the experience of extending formula interface in R, and hear how some R users have successfully combined FeatureHashing with `xgboost` to do text mining.</p>
        </div>
    </td>
</tr>


<tr>
    <td>
        <strong>尤晓斌</strong>
        <p>尤晓斌，现任新加坡国立医疗集团(National Healthcare Group)数据分析员，曾就读于新加坡国立大学统计系和厦门大学统计系。有5年的R使用经历。兴趣领域为：统计学习，数据科学，可视化以及人口医疗相关分析。Email：alex.xbyou@gmail.com，Xiaobin.you@nus.edu.sg</p>
    </td>
    <td>
        <p>新加坡医疗系统在2014年Bloomberg医疗体系效率排名中位列第一。哈佛大学医学院教授哈兹尔廷用“价廉质优”一词，形容新加坡用4%的国内生产总值交出了一流成绩单——全民医疗覆盖，低婴儿死亡率和高预期寿命。
新加坡医疗系统同样面临人口老龄化的挑战。据估计，至2030年新加坡65岁以上的人口将超总过人口的20%。为了优化医疗系统以迎接人口老龄化的挑战，新加坡积极探索区域医疗模式，纵向整合综合医院，联合诊所，社区医院及疗养院等医疗资源，形成六大区域医疗协同合作的局面。
数据科学在探索区域医疗的过程中注入了新的科技活力。数据仓库的管理整合医疗机构运营数据以及SNOMED，ICD和WHO drug dictionary等标准化编码系统；统计学习建模能综合多方面信息协助决策；可视化及GIS有助于分析成果的阐释和理解。从数据预处理，建模到最终成果展示这一流程中，R语言都扮演着重要的角色。</p>
    </td>
</tr>

  </tbody>
</table>
